{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa8ac175",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee1b5db",
   "metadata": {
    "papermill": {
     "duration": 0.003717,
     "end_time": "2025-04-11T17:07:56.943041",
     "exception": false,
     "start_time": "2025-04-11T17:07:56.939324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Metastatic Tissue Classification problem -- supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05526a",
   "metadata": {
    "papermill": {
     "duration": 0.002542,
     "end_time": "2025-04-11T17:08:08.723749",
     "exception": false,
     "start_time": "2025-04-11T17:08:08.721207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "This notebook trains and evaluate supervised models to solve the \"Metastatic Tissue Classification\" task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460e504",
   "metadata": {},
   "source": [
    "The following code block contains the main parameters for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33265c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "data_dir = \"./data\"\n",
    "\n",
    "# Configurable validation dataset size (None = all validation samples)\n",
    "DL_VAL_SAMPLES_PER_CLASS=None\n",
    "DL_NUM_WORKERS=4\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 2 ** 9\n",
    "SAMPLES_PER_CLASS_LIST = [\n",
    "    12_800,\n",
    "    25_600,\n",
    "    51_200,\n",
    "    128_000\n",
    "]\n",
    "\n",
    "n_versions = 3\n",
    "max_steps = 100 * 20\n",
    "\n",
    "add_from_scratch_models = True\n",
    "add_pretrained_models = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc291f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T11:10:25.843537Z",
     "iopub.status.busy": "2025-04-11T11:10:25.843178Z",
     "iopub.status.idle": "2025-04-11T11:10:25.849551Z",
     "shell.execute_reply": "2025-04-11T11:10:25.848405Z",
     "shell.execute_reply.started": "2025-04-11T11:10:25.843509Z"
    },
    "papermill": {
     "duration": 0.004188,
     "end_time": "2025-04-11T17:08:08.743322",
     "exception": false,
     "start_time": "2025-04-11T17:08:08.739134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "## 2. Setting up the dataset\n",
    "\n",
    "We will use the PCam data module to automatically download and handle the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa53c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igor/Desktop/mo810/course-work/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Train dataloader: size=262144}\n",
      "{Validation dataloader: size=32768}\n",
      "{Test dataloader: size=32768}\n",
      "{Predict dataloader: None}\n"
     ]
    }
   ],
   "source": [
    "from dataset_pcam import PCamDataModule\n",
    "\n",
    "datamodule = PCamDataModule(data_dir=data_dir, batch_size=BATCH_SIZE, num_workers=DL_NUM_WORKERS, val_samples_per_class=DL_VAL_SAMPLES_PER_CLASS)\n",
    "\n",
    "class_names = datamodule.full_dataset.classes\n",
    "\n",
    "print(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788e445",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Setting up the models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a5f7f",
   "metadata": {},
   "source": [
    "Let's start by writing the code to support the creation of the backbone, the prediction head, and the supervised model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea147c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from minerva.models.nets.base import SimpleSupervisedModel\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "def generate_pred_head(backbone_out_dim=1920, hidden_dim=512):\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Linear(backbone_out_dim, hidden_dim),\n",
    "        torch.nn.ReLU(),\n",
    "        torch.nn.Linear(hidden_dim, len(class_names))\n",
    "    )\n",
    "\n",
    "def build_scheduler(optimizer):\n",
    "  return {\n",
    "    \"scheduler\": torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.1),\n",
    "    \"interval\": \"epoch\",\n",
    "    \"frequency\": 1,\n",
    "    \"monitor\": \"val_loss\",\n",
    "    \"strict\": True\n",
    "  }\n",
    "\n",
    "def build_SimpleSupervisedModel(backbone):\n",
    "  return SimpleSupervisedModel(\n",
    "    backbone=backbone,\n",
    "    fc=generate_pred_head(hidden_dim=1024),\n",
    "    loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "    learning_rate=1e-3,\n",
    "    lr_scheduler=build_scheduler,\n",
    "    train_metrics={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))},\n",
    "    val_metrics  ={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))},\n",
    "    test_metrics ={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))},\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b93cf0",
   "metadata": {},
   "source": [
    "Let's also create a transform pipeline to generate modified training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca4cf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.v2 import Compose, ToImage, ToDtype, Normalize, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter, CenterCrop, RandomGrayscale\n",
    "\n",
    "precomputed_dataset_stats = {'mean': torch.tensor([0.6982, 0.5344, 0.6907]), 'std': torch.tensor([0.2343, 0.2761, 0.2113])}\n",
    "\n",
    "# Set the training set image transformation pipeline\n",
    "train_transform_pipeline = Compose([ToImage(),\n",
    "                                    ToDtype(torch.float32, scale=True),\n",
    "                                    CenterCrop(42),\n",
    "                                    RandomHorizontalFlip(),\n",
    "                                    RandomVerticalFlip(),\n",
    "                                    RandomGrayscale(),\n",
    "                                    ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "                                    Normalize(precomputed_dataset_stats[\"mean\"],\n",
    "                                              precomputed_dataset_stats[\"std\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939f1e1",
   "metadata": {},
   "source": [
    "Now, let's create models with different configurations (e.g., initial parameters), and models to be trained with different number of samples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c524a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== The following models were included ==\n",
      "  0 From_Scratch-aug/12800_spc/15000_steps/v_0\n",
      "  1 Pretrained_ImageNet-aug/12800_spc/15000_steps/v_0\n",
      "  2 From_Scratch-aug/25600_spc/15000_steps/v_0\n",
      "  3 Pretrained_ImageNet-aug/25600_spc/15000_steps/v_0\n",
      "  4 From_Scratch-aug/51200_spc/15000_steps/v_0\n",
      "  5 Pretrained_ImageNet-aug/51200_spc/15000_steps/v_0\n",
      "  6 From_Scratch-aug/128000_spc/15000_steps/v_0\n",
      "  7 Pretrained_ImageNet-aug/128000_spc/15000_steps/v_0\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "from torchvision.models import DenseNet201_Weights\n",
    "import lightning\n",
    "from pcam.backbone import generate_backbone\n",
    "\n",
    "# Let's set the seeds for reproducibility\n",
    "lightning.seed_everything(1969)\n",
    "\n",
    "for version in range(n_versions):\n",
    "    # , (\"notr\", None)\n",
    "    for train_transform_id, train_transform_pipeline in [ (\"aug\", train_transform_pipeline) ]:\n",
    "        for samples_per_class in SAMPLES_PER_CLASS_LIST:\n",
    "            # -- Add the from scratch model --\n",
    "            if add_from_scratch_models:\n",
    "                backbone = generate_backbone()\n",
    "                models[f\"From_Scratch-{train_transform_id}/{samples_per_class}_spc/{max_steps}_steps/v_{version}\"] = {\n",
    "                    \"backbone\": backbone,\n",
    "                    \"model\": build_SimpleSupervisedModel(backbone),\n",
    "                    \"max_steps\": max_steps,\n",
    "                    \"samples per class\": samples_per_class,\n",
    "                    \"train_transform\": train_transform_pipeline,\n",
    "                    \"version\": version\n",
    "                }\n",
    "\n",
    "            # -- Add the pretrained model: ImageNet weights --\n",
    "            if add_pretrained_models:\n",
    "                backbone = generate_backbone(weights=DenseNet201_Weights.IMAGENET1K_V1)\n",
    "                models[f\"Pretrained_ImageNet-{train_transform_id}/{samples_per_class}_spc/{max_steps}_steps/v_{version}\"] = {\n",
    "                    \"backbone\": backbone,\n",
    "                    \"model\": build_SimpleSupervisedModel(backbone),\n",
    "                    \"max_steps\": max_steps,\n",
    "                    \"samples per class\": samples_per_class,\n",
    "                    \"train_transform\": train_transform_pipeline,\n",
    "                    \"version\": version\n",
    "                }\n",
    "\n",
    "print(\"== The following models were included ==\")\n",
    "for i, k in enumerate(models.keys()):\n",
    "    print(f\"{i:3d} {k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc0e61",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 4. Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459823f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************\n",
      " Training model From_Scratch-aug/128000_spc/15000_steps/v_0\n",
      "***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | backbone | DenseNet         | 18.1 M | train\n",
      "1 | fc       | Sequential       | 2.0 M  | train\n",
      "2 | loss_fn  | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "20.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 M    Total params\n",
      "80.248    Total estimated model params size (MB)\n",
      "718       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 500/500 [05:46<00:00,  1.44it/s, v_num=0_1, val_loss=0.421, val_accuracy=0.820, train_loss=0.249, train_accuracy=0.897]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=15000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 500/500 [05:46<00:00,  1.44it/s, v_num=0_1, val_loss=0.421, val_accuracy=0.820, train_loss=0.249, train_accuracy=0.897]\n",
      "Loading weights from logs/PCam/Downstream/From_Scratch-aug/128000_spc/15000_steps/v_0/version_0/checkpoints/epoch=6-step=3500.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 64/64 [00:23<00:00,  2.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.8038330078125      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.43206191062927246    </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.8038330078125     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.43206191062927246   \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Training stats\n",
      "  - Avg time to train models: 10508.49 seconds \n",
      "  - Total # models  : 2 model(s)\n",
      "  - Models trained  : 1 model(s) in 10508.49 seconds\n",
      "  - Remaining models: 1 model(s). 10508.486473959056 s remaining (Estimative)\n",
      "  - Total time      : 21016.97294791811 seconds (estimate: avg * # models)\n",
      "***********************************\n",
      " Training model Pretrained_ImageNet-aug/128000_spc/15000_steps/v_0\n",
      "***********************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type             | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | backbone | DenseNet         | 18.1 M | train\n",
      "1 | fc       | Sequential       | 2.0 M  | train\n",
      "2 | loss_fn  | CrossEntropyLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "20.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 M    Total params\n",
      "80.248    Total estimated model params size (MB)\n",
      "718       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 500/500 [05:46<00:00,  1.44it/s, v_num=0_1, val_loss=0.438, val_accuracy=0.821, train_loss=0.191, train_accuracy=0.925]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=15000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 500/500 [05:46<00:00,  1.44it/s, v_num=0_1, val_loss=0.438, val_accuracy=0.821, train_loss=0.191, train_accuracy=0.925]\n",
      "Loading weights from logs/PCam/Downstream/Pretrained_ImageNet-aug/128000_spc/15000_steps/v_0/version_0/checkpoints/epoch=2-step=1500.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 64/64 [00:23<00:00,  2.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_accuracy       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       0.81298828125       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4212762713432312     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_accuracy      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      0.81298828125      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4212762713432312    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Training stats\n",
      "  - Avg time to train models: 10473.67 seconds \n",
      "  - Total # models  : 2 model(s)\n",
      "  - Models trained  : 2 model(s) in 20947.34 seconds\n",
      "  - Remaining models: 0 model(s). 0.0 s remaining (Estimative)\n",
      "  - Total time      : 20947.343069495982 seconds (estimate: avg * # models)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "# Register stats\n",
    "from timeit import default_timer as timer\n",
    "n_configs = len(models)\n",
    "n_configs_trained = 0\n",
    "start_time = timer()\n",
    "\n",
    "for model_name, model_info in models.items():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"***********************************\")\n",
    "    print(f\" Training model {model_name}\")\n",
    "    print(\"***********************************\")\n",
    "    loggers = [TensorBoardLogger(save_dir=f\"logs/PCam/Downstream/\", name=model_name),\n",
    "               CSVLogger(save_dir=f\"logs/PCam/Downstream/\", name=model_name)]\n",
    "    checkpoint_callback = ModelCheckpoint(monitor=\"val_loss\", mode=\"min\")\n",
    "    trainer = Trainer(max_steps=model_info[\"max_steps\"], benchmark=True, \n",
    "                      log_every_n_steps=8, logger=loggers,\n",
    "                      callbacks=[checkpoint_callback])\n",
    "    \n",
    "    # Train the model\n",
    "    trainer.fit(model_info[\"model\"], \n",
    "                train_dataloaders=datamodule.train_dataloader(samples_per_class=model_info[\"samples per class\"], \n",
    "                                                              transform=model_info[\"train_transform\"]),\n",
    "                val_dataloaders=datamodule.val_dataloader())\n",
    "\n",
    "    # Load parameters from best epoch\n",
    "    print(f\"Loading weights from {checkpoint_callback.best_model_path}\")\n",
    "    best_model = SimpleSupervisedModel.load_from_checkpoint(checkpoint_callback.best_model_path,\n",
    "                                                            backbone=model_info[\"model\"].backbone,\n",
    "                                                            fc=model_info[\"model\"].fc,\n",
    "                                                            loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                            train_metrics={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))},\n",
    "                                                            val_metrics  ={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))},\n",
    "                                                            test_metrics ={\"accuracy\": Accuracy(\"multiclass\", num_classes=len(class_names))})\n",
    "\n",
    "    # Test the model\n",
    "    trainer.test(best_model, dataloaders=datamodule.test_dataloader())\n",
    "\n",
    "    # Compute and display training statistics\n",
    "    elapsed = timer() - start_time\n",
    "    n_configs_trained += 1\n",
    "    avg = elapsed / n_configs_trained  \n",
    "    print(\"-----------------------------------\")\n",
    "    print(f\"Training stats\")\n",
    "    print(f\"  - Avg time to train models: {avg:.2f} seconds \")\n",
    "    est_total = avg * n_configs\n",
    "    est_remaining = est_total - elapsed\n",
    "    print(f\"  - Total # models  : {n_configs} model(s)\")\n",
    "    print(f\"  - Models trained  : {n_configs_trained} model(s) in {elapsed:.2f} seconds\")\n",
    "    print(f\"  - Remaining models: {n_configs-n_configs_trained} model(s). {est_remaining} s remaining (Estimative)\")\n",
    "    print(f\"  - Total time      : {est_total} seconds (estimate: avg * # models)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6403655,
     "sourceId": 10341279,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23625.296183,
   "end_time": "2025-04-11T23:41:38.214128",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-11T17:07:52.917945",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
